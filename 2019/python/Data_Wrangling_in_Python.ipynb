{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "1. [Read in Data as Pandas DataFrame](#Read-in-Data-as-Pandas-DataFrame)\n",
    "2. [Random Sampling](#Random-Sampling)\n",
    "3. [Renaming Axis Indexes](#Renaming-Axis-Indexes)\n",
    "4. [Indexing, Selecting and Filtering DataFrame](#Indexing,-Selecting-and-Filtering-DataFrame) \n",
    "\n",
    "**Combining and Merging Data Sets**\n",
    "\n",
    "5.  [Concatenating Along an Axis](#Concatenating-Along-an-Axis)\n",
    "6. [Database-style DataFrame Merges](#Database-style-DataFrame-Merges)\n",
    "7. [Joining/ Merging on Index](#Joining/-Merging-on-Index)\n",
    "\n",
    "**Reshaping and Pivoting**\n",
    "8. [Reshaping by Melt](#Reshaping-by-Melt)\n",
    "9. [Reshaping by pivoting](#Reshaping-by-pivoting)\n",
    "\n",
    "**Data Transformation**\n",
    "\n",
    "10. [Dealing with datetime](#Dealing-with-datetime) \n",
    "\n",
    "9. [Removing Duplicates](#Removing-Duplicates)\n",
    "\n",
    "10. [Transforming Data Using a Function or Mapping](#Transforming-Data-Using-a-Function-or-Mapping)\n",
    "\n",
    "11. [Replacing Values/ Handling Missing Values](#Replacing-Values/-Handling-Missing-Values)\n",
    "\n",
    "12. [Discretization and Binning](#Discretization-and-Binning)\n",
    "\n",
    "\n",
    "[Exercises](#Exercises)\n",
    "\n",
    "Materials are adopted from the \n",
    "- Python for Data Analysis by Wes McKinney \n",
    "- Pandas 0.24.2 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:15:15.847460Z",
     "start_time": "2019-03-29T17:15:15.845056Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "hH4LELQ3o1JJ"
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byy_nFQko2mQ"
   },
   "source": [
    "# Read in Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:21:00.615866Z",
     "start_time": "2019-03-29T17:20:59.977175Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "izoGhoyWtrh4",
    "outputId": "1a0eca07-613f-44da-be0c-c824975038df"
   },
   "outputs": [],
   "source": [
    "#print(os.getcwd())\n",
    "    \n",
    "weather_full = pd.read_csv('../data/weather_description.csv')  #(45253, 37)\n",
    "temp_full = pd.read_csv('../data/temperature.csv') # (45253, 37)\n",
    "city_full = pd.read_csv('../data/city_attributes.csv') #(36, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T04:35:56.540137Z",
     "start_time": "2019-03-29T04:35:56.515591Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T04:35:57.463535Z",
     "start_time": "2019-03-29T04:35:57.439343Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T04:35:57.771653Z",
     "start_time": "2019-03-29T04:35:57.761111Z"
    }
   },
   "outputs": [],
   "source": [
    "city_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling\n",
    "\n",
    "We might want to sample a subset of the entire dataset to do data wrangling & exploration. This is especially useful when working with large data sets.  \n",
    "\n",
    "To select a random subset without replacement, we can \n",
    "1. slice off the first k rows of the dataframe, using `pandas.DataFrame.iloc` indexing \n",
    "2. randomly sampling k rows from the dataframe, using `pandas.DataFrame.sample`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:21:11.876425Z",
     "start_time": "2019-03-29T17:21:11.852100Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 1000\n",
    "\n",
    "temp_small = temp_full.iloc[0:k]\n",
    "temp_small = temp_full.sample(n=k, replace=False, random_state=0)\n",
    "\n",
    "temp_small.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Axis Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:16:35.410072Z",
     "start_time": "2019-03-29T17:16:35.401043Z"
    }
   },
   "outputs": [],
   "source": [
    "df = city_full.set_index('City')\n",
    "df.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:16:36.032515Z",
     "start_time": "2019-03-29T17:16:36.017414Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "# Renaming Axis Indexes\n",
    "df2.index.map(str.upper)\n",
    "\n",
    "# assign to index, modifying the DataFrame in place\n",
    "df2.index = df2.index.map(str.upper)\n",
    "\n",
    "# using pandas.rename\n",
    "df2.rename(index=str.title, columns=str.upper)\n",
    "\n",
    "df2.rename(index={'San Francisco': 'SF', 'New York': 'NYC'},\n",
    "           columns={'Country': 'Nation' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing, Selecting and Filtering DataFrame\n",
    "\n",
    "- `DataFrame.filter`: Subset rows or columns of dataframe according to labels in the specified index.\n",
    "\n",
    "- `DataFrame.loc`: Access a group of rows and columns by label(s) or a boolean array.\n",
    "- `DataFrame.iloc`: Purely integer-location based indexing for selection by position.\n",
    "\n",
    "- `DataFrame.query`: Query the columns of a DataFrame with a boolean expression.\n",
    "\n",
    "\n",
    "Pandas Doc: \n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.filter.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html#pandas.DataFrame.query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:19:52.417515Z",
     "start_time": "2019-03-29T12:19:52.413399Z"
    }
   },
   "source": [
    "#### `DataFrame.filter(items=[list-like], like=[string], regex=[string (regular expression)], axis=[int/ string axis name])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:16:38.675037Z",
     "start_time": "2019-03-29T17:16:38.662667Z"
    }
   },
   "outputs": [],
   "source": [
    "# select columns by name\n",
    "\n",
    "df.filter(items=['Latitude', 'Longitude'])\n",
    "df.filter(regex='tude$', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:16:48.037253Z",
     "start_time": "2019-03-29T17:16:48.026277Z"
    }
   },
   "outputs": [],
   "source": [
    "# select rows \n",
    "\n",
    "df.filter(items=['Portland', 'Seattle'], axis=0)\n",
    "\n",
    "df.filter(like='San', axis=0)\n",
    "df.filter(regex='^San', axis=0)\n",
    "\n",
    "df.filter(regex='land$', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame.iloc[<selection>, <selection>]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:16:53.305265Z",
     "start_time": "2019-03-29T17:16:53.296007Z"
    }
   },
   "outputs": [],
   "source": [
    "city_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:16:54.002650Z",
     "start_time": "2019-03-29T17:16:53.995909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Single selections using iloc and DataFrame\n",
    "\n",
    "# Rows:\n",
    "city_full.iloc[0] # first row of data frame - Note a Series data type output.\n",
    "city_full.iloc[1] # second row of data frame \n",
    "city_full.iloc[-1] # last row of data frame\n",
    "\n",
    "# Columns:\n",
    "city_full.iloc[:,0] # first column of data frame \n",
    "city_full.iloc[:,1] # second column of data frame \n",
    "city_full.iloc[:,-1] # last column of data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:30:47.503197Z",
     "start_time": "2019-03-29T12:30:47.492704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Multiple columns and rows can be selected together using the .iloc indexer.\n",
    "\n",
    "# Multiple row and column selections using iloc and DataFrame\n",
    "city_full.iloc[0:5] # first five rows of dataframe\n",
    "city_full.iloc[:, 0:2] # first two columns of data frame with all rows\n",
    "city_full.iloc[[0,3,6,24], [2,3]] # 1st, 4th, 7th, 25th row + 3nd, 4rd columns.\n",
    "city_full.iloc[0:5, 1:] # first 5 rows and every columns from the 2nd of data frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame.loc[<selection>, <selection>]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:11:28.073947Z",
     "start_time": "2019-03-29T12:11:28.064462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Conditional that returns a boolean Series\n",
    "city_full.loc[city_full['Country'] == 'Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:13:21.492298Z",
     "start_time": "2019-03-29T12:13:21.482945Z"
    }
   },
   "outputs": [],
   "source": [
    "# ... with column labels specified\n",
    "city_full.loc[city_full['Country'] == 'Canada', ['Latitude', 'Longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T11:50:40.739257Z",
     "start_time": "2019-03-29T11:50:40.729109Z"
    }
   },
   "outputs": [],
   "source": [
    "# ... that match multiple row values\n",
    "city_full.loc[city_full['City'].isin(['New York', 'Boston'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T11:55:51.969706Z",
     "start_time": "2019-03-29T11:55:51.957103Z"
    }
   },
   "outputs": [],
   "source": [
    "# ... that match row values on different columns \n",
    "city_full.loc[city_full['City'].str.endswith(\"land\") & city_full['Country'].str.startswith(\"United\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T11:58:06.222230Z",
     "start_time": "2019-03-29T11:58:06.211296Z"
    }
   },
   "outputs": [],
   "source": [
    "# ... \n",
    "city_full.loc[(city_full['Latitude'] > 40) & (city_full['Longitude'] <= -40)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T11:59:09.641223Z",
     "start_time": "2019-03-29T11:59:09.626707Z"
    }
   },
   "outputs": [],
   "source": [
    "# A lambda function that yields True/False values can also be used.\n",
    "city_full.loc[city_full['City'].apply(lambda x: len(x.split(' ')) == 2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:00:58.092374Z",
     "start_time": "2019-03-29T12:00:58.083193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selections can be achieved outside of the main .loc for clarity:\n",
    "# Form a separate variable with your selections:\n",
    "idx = city_full['City'].apply(lambda x: len(x.split(' ')) == 2)\n",
    "\n",
    "# Select only the True values in 'idx' and the columns specified:\n",
    "city_full.loc[idx, ['City']] #.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T12:35:03.564432Z",
     "start_time": "2019-03-29T12:35:03.557279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Does it return Pandas Series or DataFrame\n",
    "\n",
    "print(type(city_full.loc[city_full['Country'] == 'Canada', 'City']))  # type Series when only one columns is selected\n",
    "print(type(city_full.loc[city_full['Country'] == 'Canada', ['City']])) # DataFrame when list selection is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataFrame.query[<expr>]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:31:57.062133Z",
     "start_time": "2019-03-29T17:31:57.051212Z"
    }
   },
   "outputs": [],
   "source": [
    "city_full.query('Country == \"Canada\" & Longitude < - 100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqF73hj8rsCZ"
   },
   "source": [
    "# Combining and Merging Data Sets \n",
    "\n",
    "Data contained in `pandas` objects can be combined together in a number of built-in ways:\n",
    "- `pandas.merge` connects rows in DataFrames based on one or more keys. \n",
    "- `pandas.join` Join columns of another DataFrame.\n",
    "- `pandas.concat` glues or stacks together objects along an axis.\n",
    "- `combine_first` instance method enables splicing together overlapping data to fill\n",
    "in missing values in one object with values from another\n",
    "\n",
    "Pandas doc: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating Along an Axis \n",
    "\n",
    "- `pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:51:42.328791Z",
     "start_time": "2019-03-29T02:51:42.185130Z"
    }
   },
   "outputs": [],
   "source": [
    "df1= temp_full.set_index('datetime').rename_axis(None)\n",
    "df2 = weather_full.set_index('datetime').rename_axis(None)\n",
    "\n",
    "result = pd.concat([df1, df2])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database-style DataFrame Merges\n",
    "\n",
    "- Merge or join operations combine data sets by linking rows using one or more keys \n",
    "- `pd.merge(left, right, how='merge method', on='key', left_on='left_key', right_on='right_key')`, \n",
    "\n",
    "\n",
    "Merge method |\tSQL Join Name\t| Description \n",
    "- | - | -\n",
    "left\t| LEFT OUTER JOIN\t| Use keys from left frame only\n",
    "right\t| RIGHT OUTER JOIN\t| Use keys from right frame only\n",
    "outer\t| FULL OUTER JOIN\t| Use union of keys from both frames\n",
    "inner\t| INNER JOIN\t    | Use intersection of keys from both frames\n",
    "         \n",
    "Pandas doc: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:17:46.787498Z",
     "start_time": "2019-03-29T17:17:46.781048Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_small = temp_full.iloc[0:k]\n",
    "\n",
    "temp_small_t = temp_small.set_index('datetime').rename_axis(None).transpose().rename_axis('City').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:17:47.125449Z",
     "start_time": "2019-03-29T17:17:47.095293Z"
    }
   },
   "outputs": [],
   "source": [
    "city_temp = pd.merge(city_full, temp_small_t, on='City')\n",
    "\n",
    "city_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T02:10:22.528767Z",
     "start_time": "2019-03-29T02:10:22.526294Z"
    }
   },
   "source": [
    "#### Checking for duplicate keys\n",
    "\n",
    "Users can use the validate argument to automatically check whether there are unexpected duplicates in their merge keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:17:48.436185Z",
     "start_time": "2019-03-29T17:17:48.425934Z"
    }
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'A' : [1,2], 'B' : [1, 2]})\n",
    "right = pd.DataFrame({'A' : [4,5,6], 'B': [2, 2, 2]})\n",
    "    \n",
    "left.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:17:48.637356Z",
     "start_time": "2019-03-29T17:17:48.629488Z"
    }
   },
   "outputs": [],
   "source": [
    "right.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:21:29.442521Z",
     "start_time": "2019-03-29T17:21:29.440111Z"
    }
   },
   "outputs": [],
   "source": [
    "#result = pd.merge(left, right, on='B', validate=\"one_to_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining/ Merging on Index \n",
    "\n",
    "- `DataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:21:45.930463Z",
     "start_time": "2019-03-29T17:21:45.921517Z"
    }
   },
   "outputs": [],
   "source": [
    "# city_full.set_index('City', inplace=True)\n",
    "# temp_small_t.set_index('City', inplace=True)\n",
    "\n",
    "city_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:21:48.525782Z",
     "start_time": "2019-03-29T17:21:48.504427Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_small_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:21:51.136601Z",
     "start_time": "2019-03-29T17:21:51.112585Z"
    }
   },
   "outputs": [],
   "source": [
    "city_temp = city_full.join(temp_small_t, on='City')\n",
    "city_temp.head()\n",
    "\n",
    "# same as\n",
    "# result = pd.merge(city_full, temp_small_t, left_index=True, right_index=True, how='left')\n",
    "# result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InneLmLPrps_"
   },
   "source": [
    "# Reshaping and Pivoting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:03:19.948656Z",
     "start_time": "2019-03-29T13:03:19.939227Z"
    }
   },
   "outputs": [],
   "source": [
    "city_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping by Melt\n",
    "\n",
    "- `pandas.melt()`: Unpivots a DataFrame from wide format to long format, optionally leaving identifier variables set.\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.melt.html#pandas.DataFrame.melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:15:43.618398Z",
     "start_time": "2019-03-29T13:15:43.612048Z"
    }
   },
   "outputs": [],
   "source": [
    "city_long = pd.melt(city_full, id_vars = ['Country', 'City']) # var_name='Lat/Long', value_name='value'\n",
    "\n",
    "# or, \n",
    "# city_full.melt(id_vars=['Country', 'City'], var_name='quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping by pivoting \n",
    "\n",
    "- `pandas.pivot` : Pivot a DataFrame from long to wide format by given index / column values.\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T13:28:12.586871Z",
     "start_time": "2019-03-29T13:28:12.575097Z"
    }
   },
   "outputs": [],
   "source": [
    "city_wide = city_long.pivot(index='City', columns='variable', values='value')\n",
    "city_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CH3R1zqrnvo"
   },
   "source": [
    "# Data Transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:22:54.825980Z",
     "start_time": "2019-03-29T17:22:54.821625Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_full['datetime'] = pd.to_datetime(weather_full['datetime'])\n",
    "\n",
    "print(weather_full['datetime'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:23:09.189145Z",
     "start_time": "2019-03-29T17:23:09.165238Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:43:52.504336Z",
     "start_time": "2019-03-29T17:43:52.479401Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start_datetime = datetime.datetime(2012,10,1, 9, 0)\n",
    "end_datetime = datetime.datetime(2012,10,1, 17, 0)\n",
    "\n",
    "\n",
    "weather_full[weather_full.datetime.between(start_datetime, end_datetime)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "\n",
    "- `DataFrame.drop_duplicates([subset, keep, 因)`: Return DataFrame with duplicate rows removed, optionally only considering certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_full.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['Vancouver', 'Canada', 49.249660, -123.119339],\n",
    "                  ['Portland', 'United States', 45.523449, -122.676208]],\n",
    "                 columns = ['City', 'Country', 'Latitude', 'Longitude'])\n",
    "city_full2 = city_full.append(df)\n",
    "city_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_full2.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_full2 = city_full2.drop_duplicates()\n",
    "city_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([['Vancouver', 'canada', 49.249660, -123.119339],\n",
    "                  ['Portland', 'United States', 45.523449, -122.676208]],\n",
    "                 columns = ['City', 'Country', 'Latitude', 'Longitude'])\n",
    "city_full2 = city_full.append(df)\n",
    "city_full2 = city_full2.drop_duplicates()\n",
    "city_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_full2.drop_duplicates(['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Data Using a Function or Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_name_len = {\n",
    "    'United States': 'twelve',\n",
    "    'Canada': 'six',\n",
    "    'Israel': 'six'\n",
    "}\n",
    "city_full['Name Length'] = city_full['Country'].map(country_to_name_len)\n",
    "city_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values/ Handling Missing Values\n",
    "\n",
    "- `DataFrame.dropna([axis, how, thresh, 因)`: Remove missing values.\n",
    "- `DataFrame.fillna([value, method, axis, 因)`:\tFill NA/NaN values using the specified method.\n",
    "- `DataFrame.replace([to_replace, value, 因)`:\tReplace values given in to_replace with value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_full2 = city_full.replace('twelve', 12)\n",
    "city_full2 = city_full2.replace('six', 6)\n",
    "city_full2\n",
    "\n",
    "city_full2 = city_full2.replace(['twelve', 'six'], [12, 6])\n",
    "city_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.replace(np.nan, 'no data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_values = {'Vancouver': 0, 'Portland': 1} #Replace NA's in each column with different values\n",
    "temp_full.fillna(value = na_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.fillna(value=na_values, limit=1) #replace only the first NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.dropna() #drop rows with at least one element missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.dropna(axis = 'columns') #drop columns with at least one element missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_full.dropna(how = 'all') #drop rows where all elements are missing\n",
    "temp_full.dropna(thresh = 2) #drop rows with at least 2 non-NA values\n",
    "temp_full.dropna(subset = ['Vancouver', 'Portland']) #drop rows where elements are missing in any columns specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization and Binning\n",
    "\n",
    "- `pandas.cut` Bin values into discrete intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(230, 330, 5))\n",
    "\n",
    "temp_full2 = pd.read_csv('../data/temperature.csv')\n",
    "\n",
    "temp_full2['Vancouver'] = pd.cut(temp_full2['Vancouver'], bins)\n",
    "temp_full2['Portland'] = pd.cut(temp_full2['Portland'], bins)\n",
    "temp_full2['San Francisco'] = pd.cut(temp_full2['San Francisco'], bins)\n",
    "temp_full2['Seattle'] = pd.cut(temp_full2['Seattle'], bins)\n",
    "temp_full2['Los Angeles'] = pd.cut(temp_full2['Los Angeles'], bins)\n",
    "temp_full2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "\n",
    "Output a dataframe with the temperatures in year 2013 of the cities in Canada.\n",
    "\n",
    "Hint 1: we would need to transpose the `temp_full` table \n",
    "\n",
    "Hint 2: Information of country & cities is in `city_full` while information temperature & cities is in `temp_full`, hence we would need need to merge these two tables before filtering for `Country == \"Canada\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Write your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Highest temprature in each cities between year 2013 and 2014.\n",
    "\n",
    "Hint 1: `index.dt.month in [6, 7, 8, 9]`, `index.dt.year in [2013, 2014]\")` in `pd.query`\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.year.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.month.html\n",
    "\n",
    "Hint 2: use `Pandas.max`: http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-29T17:47:04.544659Z",
     "start_time": "2019-03-29T17:47:04.535598Z"
    }
   },
   "outputs": [],
   "source": [
    "#  Write your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Python_Data_Wrangling.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
